{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f64a236-060b-4648-89fb-8ad86addde67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "!pip3 install -q --upgrade pip\n",
    "!pip3 install -q google-cloud-aiplatform\n",
    "!pip3 install -q langchain\n",
    "!pip3 install -q langchain-community\n",
    "!pip3 install -q lxml\n",
    "!pip3 install -q requests\n",
    "!pip3 install -q beautifulsoup4\n",
    "!pip3 install -q unstructured\n",
    "!pip3 install -q langchain-google-genai\n",
    "!pip3 install -q google-generativeai\n",
    "!pip3 install -q tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b371c287-5c4d-4f6d-9483-787ddb7a79c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart the kernel\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ac7c23-8831-4594-a9aa-a1aade9da542",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f13fb6-6a06-4dcb-9812-4643cb1f9cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import textwrap\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d754a634-726f-4e04-bbec-ff241cfbdb74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# source API key from GCP project and configure genai client\n",
    "import os\n",
    "import pathlib\n",
    "import textwrap\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "key_name = !gcloud services api-keys list --filter=\"gemini-api-key\" --format=\"value(name)\"\n",
    "key_name = key_name[0]\n",
    "\n",
    "api_key = !gcloud services api-keys get-key-string $key_name --location=\"us-central1\" --format=\"value(keyString)\"\n",
    "api_key = api_key[0]\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3200270-2efd-44d6-8aba-8d141b88a15c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/802092767636/locations/global/keys/gemini-api-key'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6615826b-2f56-489d-9a24-6c0f696ad8fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIzaSyCO7VV8vj90-J-5iAqr4FUQdA7pDUe1cdk'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db35058-5ee4-4eda-94d1-1c8fa96235fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your project ID is: qwiklabs-gcp-00-f934b9efbd16\n"
     ]
    }
   ],
   "source": [
    "# Define project information\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "PROJECT_ID = subprocess.check_output([\"gcloud\", \"config\", \"get-value\", \"project\"], text=True).strip()\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "print(f\"Your project ID is: {PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9781195e-7ab6-455b-9397-e166352bfb09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set environment vars\n",
    "BUCKET = f\"gs://{PROJECT_ID}/embeddings\"\n",
    "DIMENSIONS=768\n",
    "DISPLAY_NAME='vertex_docs_qa'\n",
    "ENDPOINT=f\"{REGION}-aiplatform.googleapis.com\"\n",
    "TEXT_GENERATION_MODEL='gemini-pro'\n",
    "SITEMAP='https://docs.anthropic.com/sitemap.xml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15d201b-404b-4fbb-8ff2-7e45096ab2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f243a82-fb52-4874-a921-978a5a2769c4",
   "metadata": {},
   "source": [
    "# Task 1: Create Documents from Vertex AI Cloud Documentation Site\n",
    "\n",
    "## Load and parse sitemap.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6c90bd-1d13-4b5b-baaa-9d17b6097b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse the xml of sitemap and get URLs of doc site\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_sitemap(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"xml\")\n",
    "    urls = [element.text for element in soup.find_all(\"loc\")]\n",
    "    return urls\n",
    "\n",
    "sites = parse_sitemap(SITEMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df3127cc-af41-4afb-a183-9165bce92b98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://docs.anthropic.com/de/api/claude-on-amazon-bedrock',\n",
       " 'https://docs.anthropic.com/de/api/claude-on-vertex-ai',\n",
       " 'https://docs.anthropic.com/de/api/client-sdks']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a375b356-263c-481a-89eb-19eeacbf2088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use this to filter out docs that don't have a corresponding reference page\n",
    "sites_filtered = [url for url in sites if '/en/docs' in url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c956153-9c15-42b2-83fc-6c30c13d21c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sites_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc151f1f-0416-4421-909d-b792750220d2",
   "metadata": {},
   "source": [
    "## Load documentation pages using the LangChain UnstructuredURLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82632343-60bd-4c3c-a39d-ae728f75d1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This step will take a few minutes to complete\n",
    "# you will see download messages below the cell after execution\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "loader = UnstructuredURLLoader(urls=sites_filtered)\n",
    "documents = loader.load();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a4bea38-237a-409f-b38b-6836511ddece",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.anthropic.com/en/docs/about-claude/models'}, page_content='Anthropic home page\\n\\nLearn about Claude\\n\\nModels\\n\\nUser GuidesAPI ReferencePrompt LibraryRelease NotesBuild with Claude Contest\\n\\nDeveloper Console\\n\\nDeveloper Discord\\n\\nSupport\\n\\nGet started\\n\\nOverview\\n\\nQuickstart\\n\\nIntro to Claude\\n\\nLearn about Claude\\n\\nUse cases\\n\\nModels\\n\\nSecurity and compliance\\n\\nBuild with Claude\\n\\nDefine success criteria\\n\\nDevelop test cases\\n\\nPrompt engineering\\n\\nText generation\\n\\nEmbeddings\\n\\nGoogle Sheets add-on\\n\\nVision\\n\\nTool use (function calling)\\n\\nTest and evaluate\\n\\nStrengthen guardrails\\n\\nUsing the Evaluation Tool\\n\\nResources\\n\\nGlossary\\n\\nSystem status\\n\\nClaude 3 model card\\n\\nAnthropic Cookbook\\n\\nAnthropic Courses\\n\\nLearn about Claude\\n\\nModels\\n\\nClaude is a family of state-of-the-art large language models developed by Anthropic. This guide introduces our models and compares their performance with legacy models.\\n\\nClaude 3.5 Haiku\\n\\nLater this year\\n\\nClaude 3.5 Sonnet\\n\\nOur most intelligent model\\n\\nText and image input Text output 200k context window\\n\\nClaude 3.5 Opus\\n\\nLater this year\\n\\nClaude 3 Haiku\\n\\nFast and cost-effective\\n\\nText and image input Text output 200k context window\\n\\nClaude 3 Sonnet\\n\\nBalance of speed and intelligence\\n\\nText and image input Text output 200k context window\\n\\nClaude 3 Opus\\n\\nExcels at writing and complex tasks\\n\\nText and image input Text output 200k context window\\n\\nModel names\\n\\nModel Anthropic API AWS Bedrock GCP Vertex AI Claude 3.5 Opus Later this year Later this year Later this year Claude 3.5 Sonnet claude-3-5-sonnet-20240620 anthropic.claude-3-5-sonnet-20240620-v1:0 claude-3-5-sonnet@20240620 Claude 3.5 Haiku Later this year Later this year Later this year\\n\\nModel Anthropic API AWS Bedrock GCP Vertex AI Claude 3 Opus claude-3-opus-20240229 anthropic.claude-3-opus-20240229-v1:0 claude-3-opus@20240229 Claude 3 Sonnet claude-3-sonnet-20240229 anthropic.claude-3-sonnet-20240229-v1:0 claude-3-sonnet@20240229 Claude 3 Haiku claude-3-haiku-20240307 anthropic.claude-3-haiku-20240307-v1:0 claude-3-haiku@20240307\\n\\nModel comparison\\n\\nHere is a visualization comparing cost vs. speed across Claude 3 and 3.5 models, showcasing the range in tradeoffs between cost and intelligence:\\n\\nTo help you choose the right model for your needs, weâ€™ve compiled a table comparing the key features and capabilities of each model in the Claude family:\\n\\nClaude 3.5 Sonnet Claude 3 Opus Claude 3 Sonnet Claude 3 Haiku Description Most intelligent model Powerful model for highly complex tasks Balance of intelligence and speed Fastest and most compact model for near-instant responsiveness Strengths Highest level of intelligence and capability Top-level performance, intelligence, fluency, and understanding Strong utility, balanced for scaled deployments Quick and accurate targeted performance Multilingual Yes Yes Yes Yes Vision Yes Yes Yes Yes API model name claude-3-5-sonnet-20240620 claude-3-opus-20240229 claude-3-sonnet-20240229 claude-3-haiku-20240307 API format Messages API Messages API Messages API Messages API Comparative latency Fast Moderately fast Fast Fastest Context window 200K 200K 200K 200K Max output 8192 tokens 1 4096 tokens 4096 tokens 4096 tokens Cost (Input / Output per MTok ) $3.00 / $15.00 $15.00 / $75.00 $3.00 / $15.00 $0.25 / $1.25 Training data cut-off Apr 2024 Aug 2023 Aug 2023 Aug 2023\\n\\n8192 output tokens is in beta and requires the header anthropic-beta: max-tokens-3-5-sonnet-2024-07-15. If the header is not specified, the limit is 4096 tokens.\\n\\nPrompt and output performance\\n\\nThe Claude 3 family excels in:\\n\\n\\u200bBenchmark performance: Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing. See the Claude 3 model card for more information.\\n\\nEngaging responses: Claude 3 models are ideal for applications that require rich, human-like interactions.\\n\\nIf you prefer more concise responses, you can adjust your prompts to guide the model toward the desired output length. Refer to our prompt engineering guides for details.\\n\\nOutput quality: When migrating from previous model generations to the Claude 3 family, you may notice larger improvements in overall performance.\\n\\nLegacy models\\n\\nWe recommend migrating to the Claude 3 family of models. However, we understand that some users may need time to transition from our legacy models:\\n\\nClaude Instant 1.2: A fast and efficient model predecessor of Claude Haiku.\\n\\nClaude 2.0: The strong-performing predecessor to Claude 3.\\n\\nClaude 2.1: An updated version of Claude 2 with improved accuracy and consistency.\\n\\nThese models do not have the vision capabilities of the Claude 3 family and are generally slower, less performant and intelligent.\\n\\nWhile there are no plans yet to sunset legacy models, we still recommend migrating to the Claude 3 family to take advantage of cutting-edge features and model improvements.\\n\\nLegacy model comparison\\n\\nTo help you choose the right model for your needs, this table compares key features and capabilities.\\n\\nClaude 2.1 Claude 2 Claude Instant 1.2 Description Updated version of Claude 2 with improved accuracy Predecessor to Claude 3, offering strong all-round performance Our cheapest small and fast model, a predecessor of Claude Haiku Strengths Legacy model - performs less well than Claude 3 models Legacy model - performs less well than Claude 3 models Legacy model - performs less well than Claude 3 models Multilingual Yes, with less coverage, understanding, and skill than Claude 3 Yes, with less coverage, understanding, and skill than Claude 3 Yes, with less coverage, understanding, and skill than Claude 3 Vision No No No API model name claude-2.1 claude-2.0 claude-instant-1.2 API format Messages & Text Completions API Messages & Text Completions API Messages & Text Completions API Comparative latency Slower than Claude 3 model of similar intelligence Slower than Claude 3 model of similar intelligence Slower than Claude 3 model of similar intelligence Context window 200K 100K 100K Max output 4096 tokens 4096 tokens 4096 tokens Cost (Input / Output per MTok ) $8.00 / $24.00 $8.00 / $24.00 $0.80 / $2.40 Training data cut-off Early 2023 Early 2023 Early 2023\\n\\nGet started with Claude\\n\\nIf youâ€™re ready to start exploring what Claude can do for you, letâ€™s dive in! Whether youâ€™re a developer looking to integrate Claude into your applications or a user wanting to experience the power of AI firsthand, weâ€™ve got you covered.\\n\\nCheck out our quickstart guide for step-by-step instructions on how to get up and running with Claude. Youâ€™ll learn how to create an account, obtain API keys, and start interacting with our models in no time. You can also head over to claude.ai or our web Console to start experimenting with Claude right away!\\n\\nIf you have any questions or need assistance, donâ€™t hesitate to reach out to our support team or consult the Discord community.\\n\\nTicket routingSecurity and compliance\\n\\nxlinkedin\\n\\nOn this page\\n\\nModel names\\n\\nModel comparison\\n\\nPrompt and output performance\\n\\nLegacy models\\n\\nLegacy model comparison\\n\\nGet started with Claude'),\n",
       " Document(metadata={'source': 'https://docs.anthropic.com/en/docs/about-claude/use-cases/classification'}, page_content='Anthropic home page\\n\\nUse cases\\n\\nClassification\\n\\nUser GuidesAPI ReferencePrompt LibraryRelease NotesBuild with Claude Contest\\n\\nDeveloper Console\\n\\nDeveloper Discord\\n\\nSupport\\n\\nGet started\\n\\nOverview\\n\\nQuickstart\\n\\nIntro to Claude\\n\\nLearn about Claude\\n\\nUse cases\\n\\nOverview\\n\\nClassification\\n\\nContent moderation\\n\\nTicket routing\\n\\nModels\\n\\nSecurity and compliance\\n\\nBuild with Claude\\n\\nDefine success criteria\\n\\nDevelop test cases\\n\\nPrompt engineering\\n\\nText generation\\n\\nEmbeddings\\n\\nGoogle Sheets add-on\\n\\nVision\\n\\nTool use (function calling)\\n\\nTest and evaluate\\n\\nStrengthen guardrails\\n\\nUsing the Evaluation Tool\\n\\nResources\\n\\nGlossary\\n\\nSystem status\\n\\nClaude 3 model card\\n\\nAnthropic Cookbook\\n\\nAnthropic Courses\\n\\nUse cases\\n\\nClassification\\n\\nClaude excels at processing, understanding, and recognizing patterns in text, images, and data. These capabilities make Claude especially powerful for classification tasks.\\n\\nThis guide walks through the process of determining the best approach for building a classifier with Claude and the essentials of end-to-end deployment for a Claude classifier, from use case exploration to back-end integration.\\n\\nVisit our classification cookbooks to see example classification implementations using Claude.\\n\\nWhen to use Claude for classification\\n\\nWhen should you consider using an LLM instead of a traditional ML approach for your classification tasks? Here are some key indicators:\\n\\nRule-based classes: Use Claude when classes are defined by conditions rather than examples, as it can understand underlying rules.\\n\\nEvolving classes: Claude adapts well to new or changing domains with emerging classes and shifting boundaries.\\n\\nUnstructured inputs: Claude can handle large volumes of unstructured text inputs of varying lengths.\\n\\nLimited labeled examples: With few-shot learning capabilities, Claude learns accurately from limited labeled training data.\\n\\nReasoning Requirements: Claude excels at classification tasks requiring semantic understanding, context, and higher-level reasoning.\\n\\nEstablish your classification use case\\n\\nBelow is a non-exhaustive list of common classification use cases where Claude excels by industry.\\n\\nContent moderation: automatically identify and flag inappropriate, offensive, or harmful content in user-generated text, images, or videos.\\n\\nBug prioritization: calassify software bug reports based on their severity, impact, or complexity to prioritize development efforts and allocate resources effectively.\\n\\nIntent analysis: determine what the user wants to achieve or what action they want the system to perform based on their text inputs.\\n\\nSupport ticket routing: analyze customer interactions, such as call center transcripts or support tickets, to route issues to the appropriate teams, prioritize critical cases, and identify recurring problems for proactive resolution.\\n\\nPatient triaging: classify customer intake conversations and data according to the urgency, topic, or required expertise for efficient triaging.\\n\\nClinical trial screening: analyze patient data and medical records to identify and categorize eligible participants based on specified inclusion and exclusion criteria.\\n\\nFraud detection: identify suspicious patterns or anomalies in financial transactions, insurance claims, or user behavior to prevent and mitigate fraudulent activities.\\n\\nCredit risk assessment: classify loan applicants based on their creditworthiness into risk categories to automate credit decisions and optimize lending processes.\\n\\nLegal document categorization: classify legal documents, such as pleadings, motions, briefs, or memoranda, based on their document type, purpose, or relevance to specific cases or clients.\\n\\nImplement Claude for classification\\n\\nThe three key model decision factors are: intelligence, latency, and price.\\n\\nFor classification, a smaller model like Claude 3 Haiku is typically ideal due to its speed and efficiency. Though, for classification tasks where specialized knowledge or complex reasoning is required, Sonnet or Opus may be a better choice. Learn more about how Opus, Sonnet, and Haiku compare here.\\n\\nUse evaluations to gauge whether a Claude model is performing well enough to launch into production.\\n\\n1. Build a strong input prompt\\n\\nWhile Claude offers high-level baseline performance out of the box, a strong input prompt helps get the best results.\\n\\nFor a generic classifier that you can adapt to your specific use case, copy the starter prompt below:\\n\\nYou will be building a text classifier that can automatically categorize text into a set of predefined categories. \\nHere are the categories the classifier will use:\\n\\n<categories>\\n{{CATEGORIES}}\\n</categories>\\n\\nTo help you understand how to classify text into these categories, here are some example texts that have already been labeled with their correct category:\\n\\n<examples>\\n{{EXAMPLES}}\\n</examples>\\n\\nPlease carefully study these examples to identify the key features and characteristics that define each category. Write out your analysis of each category inside <category_analysis> tags, explaining the main topics, themes, writing styles, etc. that seem to be associated with each one.\\n\\nOnce you feel you have a good grasp of the categories, your task is to build a classifier that can take in new, unlabeled texts and output a prediction of which category it most likely belongs to.\\n\\nBefore giving your final classification, show your step-by-step process and reasoning inside <classification_process> tags. Weigh the evidence for each potential category.\\n\\nThen output your final <classification> for which category you think the example text belongs to.\\n\\nThe goal is to build a classifier that can accurately categorize new texts into the most appropriate category, as defined by the examples.\\n\\nWe also provide a wide range of prompts to get you started in our prompt library, including prompts for a number of classification use cases, including:\\n\\nSentiment Analysis\\n\\nDetect the tone and sentiment behind tweets. Understand user emotions, opinions, and reactions in real-time.\\n\\nCustomer Review Classification\\n\\nCategorize feedback into pre-specified tags. Streamline product insights and customer service responses.\\n\\n2. Develop your test cases\\n\\nTo run your classification evaluation, you will need test cases to run it on. Take a look at our guide to developing test cases.\\n\\n3. Run your eval\\n\\nEvaluation metrics\\n\\nSome success metrics to consider evaluating Claudeâ€™s performance on a classification task include:\\n\\nCriteria Description Accuracy The modelâ€™s output exactly matches the golden answer or correctly classifies the input according to the taskâ€™s requirements. This is typically calculated as (Number of correct predictions) / (Overall number of predictions). F1 Score The modelâ€™s output optimally balances precision and recall. Consistency The modelâ€™s output is consistent with its predictions for similar inputs or follows a logical pattern. Structure The modelâ€™s output follows the expected format or structure, making it easy to parse and interpret. For example, many classifiers are expected to output JSON format. Speed The model provides a response within the acceptable time limit or latency threshold for the task. Bias and Fairness If classifying data about people, is it important that the model does not demonstrate any biases based on gender, ethnicity, or other characteristics that would lead to its misclassification.\\n\\nDeploy your classifier\\n\\nTo see code examples of how to use Claude for classification, check out the Classification Guide in the Anthropic Cookbook.\\n\\nOverviewContent moderation\\n\\nxlinkedin\\n\\nOn this page\\n\\nWhen to use Claude for classification\\n\\nEstablish your classification use case\\n\\nImplement Claude for classification\\n\\n1. Build a strong input prompt\\n\\n2. Develop your test cases\\n\\n3. Run your eval\\n\\nEvaluation metrics\\n\\nDeploy your classifier')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d537a9e4-85e1-44c8-9c91-fd32bc527566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Anthropic home page\n",
       "> \n",
       "> Use cases\n",
       "> \n",
       "> Classification\n",
       "> \n",
       "> User GuidesAPI ReferencePrompt LibraryRelease NotesBuild with Claude Contest\n",
       "> \n",
       "> Developer Console\n",
       "> \n",
       "> Developer Discord\n",
       "> \n",
       "> Support\n",
       "> \n",
       "> Get started\n",
       "> \n",
       "> Overview\n",
       "> \n",
       "> Quickstart\n",
       "> \n",
       "> Intro to Claude\n",
       "> \n",
       "> Learn about Claude\n",
       "> \n",
       "> Use cases\n",
       "> \n",
       "> Overview\n",
       "> \n",
       "> Classification\n",
       "> \n",
       "> Content moderation\n",
       "> \n",
       "> Ticket routing\n",
       "> \n",
       "> Models\n",
       "> \n",
       "> Security and compliance\n",
       "> \n",
       "> Build with Claude\n",
       "> \n",
       "> Define success criteria\n",
       "> \n",
       "> Develop test cases\n",
       "> \n",
       "> Prompt engineering\n",
       "> \n",
       "> Text generation\n",
       "> \n",
       "> Embeddings\n",
       "> \n",
       "> Google Sheets add-on\n",
       "> \n",
       "> Vision\n",
       "> \n",
       "> Tool use (function calling)\n",
       "> \n",
       "> Test and evaluate\n",
       "> \n",
       "> Strengthen guardrails\n",
       "> \n",
       "> Using the Evaluation Tool\n",
       "> \n",
       "> Resources\n",
       "> \n",
       "> Glossary\n",
       "> \n",
       "> System status\n",
       "> \n",
       "> Claude 3 model card\n",
       "> \n",
       "> Anthropic Cookbook\n",
       "> \n",
       "> Anthropic Courses\n",
       "> \n",
       "> Use cases\n",
       "> \n",
       "> Classification\n",
       "> \n",
       "> Claude excels at processing, understanding, and recognizing patterns in text, images, and data. These capabilities make Claude especially powerful for classification tasks.\n",
       "> \n",
       "> This guide walks through the process of determining the best approach for building a classifier with Claude and the essentials of end-to-end deployment for a Claude classifier, from use case exploration to back-end integration.\n",
       "> \n",
       "> Visit our classification cookbooks to see example classification implementations using Claude.\n",
       "> \n",
       "> When to use Claude for classification\n",
       "> \n",
       "> When should you consider using an LLM instead of a traditional ML approach for your classification tasks? Here are some key indicators:\n",
       "> \n",
       "> Rule-based classes: Use Claude when classes are defined by conditions rather than examples, as it can understand underlying rules.\n",
       "> \n",
       "> Evolving classes: Claude adapts well to new or changing domains with emerging classes and shifting boundaries.\n",
       "> \n",
       "> Unstructured inputs: Claude can handle large volumes of unstructured text inputs of varying lengths.\n",
       "> \n",
       "> Limited labeled examples: With few-shot learning capabilities, Claude learns accurately from limited labeled training data.\n",
       "> \n",
       "> Reasoning Requirements: Claude excels at classification tasks requiring semantic understanding, context, and higher-level reasoning.\n",
       "> \n",
       "> Establish your classification use case\n",
       "> \n",
       "> Below is a non-exhaustive list of common classification use cases where Claude excels by industry.\n",
       "> \n",
       "> Content moderation: automatically identify and flag inappropriate, offensive, or harmful content in user-generated text, images, or videos.\n",
       "> \n",
       "> Bug prioritization: calassify software bug reports based on their severity, impact, or complexity to prioritize development efforts and allocate resources effectively.\n",
       "> \n",
       "> Intent analysis: determine what the user wants to achieve or what action they want the system to perform based on their text inputs.\n",
       "> \n",
       "> Support ticket routing: analyze customer interactions, such as call center transcripts or support tickets, to route issues to the appropriate teams, prioritize critical cases, and identify recurring problems for proactive resolution.\n",
       "> \n",
       "> Patient triaging: classify customer intake conversations and data according to the urgency, topic, or required expertise for efficient triaging.\n",
       "> \n",
       "> Clinical trial screening: analyze patient data and medical records to identify and categorize eligible participants based on specified inclusion and exclusion criteria.\n",
       "> \n",
       "> Fraud detection: identify suspicious patterns or anomalies in financial transactions, insurance claims, or user behavior to prevent and mitigate fraudulent activities.\n",
       "> \n",
       "> Credit risk assessment: classify loan applicants based on their creditworthiness into risk categories to automate credit decisions and optimize lending processes.\n",
       "> \n",
       "> Legal document categorization: classify legal documents, such as pleadings, motions, briefs, or memoranda, based on their document type, purpose, or relevance to specific cases or clients.\n",
       "> \n",
       "> Implement Claude for classification\n",
       "> \n",
       "> The three key model decision factors are: intelligence, latency, and price.\n",
       "> \n",
       "> For classification, a smaller model like Claude 3 Haiku is typically ideal due to its speed and efficiency. Though, for classification tasks where specialized knowledge or complex reasoning is required, Sonnet or Opus may be a better choice. Learn more about how Opus, Sonnet, and Haiku compare here.\n",
       "> \n",
       "> Use evaluations to gauge whether a Claude model is performing well enough to launch into production.\n",
       "> \n",
       "> 1. Build a strong input prompt\n",
       "> \n",
       "> While Claude offers high-level baseline performance out of the box, a strong input prompt helps get the best results.\n",
       "> \n",
       "> For a generic classifier that you can adapt to your specific use case, copy the starter prompt below:\n",
       "> \n",
       "> You will be building a text classifier that can automatically categorize text into a set of predefined categories. \n",
       "> Here are the categories the classifier will use:\n",
       "> \n",
       "> <categories>\n",
       "> {{CATEGORIES}}\n",
       "> </categories>\n",
       "> \n",
       "> To help you understand how to classify text into these categories, here are some example texts that have already been labeled with their correct category:\n",
       "> \n",
       "> <examples>\n",
       "> {{EXAMPLES}}\n",
       "> </examples>\n",
       "> \n",
       "> Please carefully study these examples to identify the key features and characteristics that define each category. Write out your analysis of each category inside <category_analysis> tags, explaining the main topics, themes, writing styles, etc. that seem to be associated with each one.\n",
       "> \n",
       "> Once you feel you have a good grasp of the categories, your task is to build a classifier that can take in new, unlabeled texts and output a prediction of which category it most likely belongs to.\n",
       "> \n",
       "> Before giving your final classification, show your step-by-step process and reasoning inside <classification_process> tags. Weigh the evidence for each potential category.\n",
       "> \n",
       "> Then output your final <classification> for which category you think the example text belongs to.\n",
       "> \n",
       "> The goal is to build a classifier that can accurately categorize new texts into the most appropriate category, as defined by the examples.\n",
       "> \n",
       "> We also provide a wide range of prompts to get you started in our prompt library, including prompts for a number of classification use cases, including:\n",
       "> \n",
       "> Sentiment Analysis\n",
       "> \n",
       "> Detect the tone and sentiment behind tweets. Understand user emotions, opinions, and reactions in real-time.\n",
       "> \n",
       "> Customer Review Classification\n",
       "> \n",
       "> Categorize feedback into pre-specified tags. Streamline product insights and customer service responses.\n",
       "> \n",
       "> 2. Develop your test cases\n",
       "> \n",
       "> To run your classification evaluation, you will need test cases to run it on. Take a look at our guide to developing test cases.\n",
       "> \n",
       "> 3. Run your eval\n",
       "> \n",
       "> Evaluation metrics\n",
       "> \n",
       "> Some success metrics to consider evaluating Claudeâ€™s performance on a classification task include:\n",
       "> \n",
       "> Criteria Description Accuracy The modelâ€™s output exactly matches the golden answer or correctly classifies the input according to the taskâ€™s requirements. This is typically calculated as (Number of correct predictions) / (Overall number of predictions). F1 Score The modelâ€™s output optimally balances precision and recall. Consistency The modelâ€™s output is consistent with its predictions for similar inputs or follows a logical pattern. Structure The modelâ€™s output follows the expected format or structure, making it easy to parse and interpret. For example, many classifiers are expected to output JSON format. Speed The model provides a response within the acceptable time limit or latency threshold for the task. Bias and Fairness If classifying data about people, is it important that the model does not demonstrate any biases based on gender, ethnicity, or other characteristics that would lead to its misclassification.\n",
       "> \n",
       "> Deploy your classifier\n",
       "> \n",
       "> To see code examples of how to use Claude for classification, check out the Classification Guide in the Anthropic Cookbook.\n",
       "> \n",
       "> OverviewContent moderation\n",
       "> \n",
       "> xlinkedin\n",
       "> \n",
       "> On this page\n",
       "> \n",
       "> When to use Claude for classification\n",
       "> \n",
       "> Establish your classification use case\n",
       "> \n",
       "> Implement Claude for classification\n",
       "> \n",
       "> 1. Build a strong input prompt\n",
       "> \n",
       "> 2. Develop your test cases\n",
       "> \n",
       "> 3. Run your eval\n",
       "> \n",
       "> Evaluation metrics\n",
       "> \n",
       "> Deploy your classifier\n",
       "> \n",
       "> Source: https://docs.anthropic.com/en/docs/about-claude/use-cases/classification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(documents[1].page_content + \"\\n\\nSource: \" + documents[1].metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cacb3e49-cd62-4043-9440-5013eb1797b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f00b5-4022-467e-a001-008b8a53768c",
   "metadata": {},
   "source": [
    "## Create Document chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4eccee30-c90b-4243-a445-53950364b3c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number documents 33\n",
      "Number chunks 197\n"
     ]
    }
   ],
   "source": [
    "# recursively loop through the text and create document chunks for embedding\n",
    "import warnings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    #separator = \"\\n\",\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 100)\n",
    "\n",
    "document_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Number documents {len(documents)}\")\n",
    "print(f\"Number chunks {len(document_chunks)}\")\n",
    "\n",
    "document_chunks=[f\"content: {chunk.page_content}, source: {chunk.metadata['source']}\" for chunk in document_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24d8fe81-6dc1-41f9-8df0-0564cbd04ea4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content: Anthropic home page\\n\\nLearn about Claude\\n\\nModels\\n\\nUser GuidesAPI ReferencePrompt LibraryRelease NotesBuild with Claude Contest\\n\\nDeveloper Console\\n\\nDeveloper Discord\\n\\nSupport\\n\\nGet started\\n\\nOverview\\n\\nQuickstart\\n\\nIntro to Claude\\n\\nLearn about Claude\\n\\nUse cases\\n\\nModels\\n\\nSecurity and compliance\\n\\nBuild with Claude\\n\\nDefine success criteria\\n\\nDevelop test cases\\n\\nPrompt engineering\\n\\nText generation\\n\\nEmbeddings\\n\\nGoogle Sheets add-on\\n\\nVision\\n\\nTool use (function calling)\\n\\nTest and evaluate\\n\\nStrengthen guardrails\\n\\nUsing the Evaluation Tool\\n\\nResources\\n\\nGlossary\\n\\nSystem status\\n\\nClaude 3 model card\\n\\nAnthropic Cookbook\\n\\nAnthropic Courses\\n\\nLearn about Claude\\n\\nModels\\n\\nClaude is a family of state-of-the-art large language models developed by Anthropic. This guide introduces our models and compares their performance with legacy models.\\n\\nClaude 3.5 Haiku\\n\\nLater this year\\n\\nClaude 3.5 Sonnet\\n\\nOur most intelligent model\\n\\nText and image input Text output 200k context window\\n\\nClaude 3.5 Opus\\n\\nLater this year\\n\\nClaude 3 Haiku\\n\\nFast and cost-effective\\n\\nText and image input Text output 200k context window\\n\\nClaude 3 Sonnet\\n\\nBalance of speed and intelligence\\n\\nText and image input Text output 200k context window\\n\\nClaude 3 Opus\\n\\nExcels at writing and complex tasks\\n\\nText and image input Text output 200k context window\\n\\nModel names\\n\\nModel Anthropic API AWS Bedrock GCP Vertex AI Claude 3.5 Opus Later this year Later this year Later this year Claude 3.5 Sonnet claude-3-5-sonnet-20240620 anthropic.claude-3-5-sonnet-20240620-v1:0 claude-3-5-sonnet@20240620 Claude 3.5 Haiku Later this year Later this year Later this year\\n\\nModel Anthropic API AWS Bedrock GCP Vertex AI Claude 3 Opus claude-3-opus-20240229 anthropic.claude-3-opus-20240229-v1:0 claude-3-opus@20240229 Claude 3 Sonnet claude-3-sonnet-20240229 anthropic.claude-3-sonnet-20240229-v1:0 claude-3-sonnet@20240229 Claude 3 Haiku claude-3-haiku-20240307 anthropic.claude-3-haiku-20240307-v1:0 claude-3-haiku@20240307\\n\\nModel comparison, source: https://docs.anthropic.com/en/docs/about-claude/models',\n",
       " 'content: Model comparison\\n\\nHere is a visualization comparing cost vs. speed across Claude 3 and 3.5 models, showcasing the range in tradeoffs between cost and intelligence:\\n\\nTo help you choose the right model for your needs, weâ€™ve compiled a table comparing the key features and capabilities of each model in the Claude family:\\n\\nClaude 3.5 Sonnet Claude 3 Opus Claude 3 Sonnet Claude 3 Haiku Description Most intelligent model Powerful model for highly complex tasks Balance of intelligence and speed Fastest and most compact model for near-instant responsiveness Strengths Highest level of intelligence and capability Top-level performance, intelligence, fluency, and understanding Strong utility, balanced for scaled deployments Quick and accurate targeted performance Multilingual Yes Yes Yes Yes Vision Yes Yes Yes Yes API model name claude-3-5-sonnet-20240620 claude-3-opus-20240229 claude-3-sonnet-20240229 claude-3-haiku-20240307 API format Messages API Messages API Messages API Messages API Comparative latency Fast Moderately fast Fast Fastest Context window 200K 200K 200K 200K Max output 8192 tokens 1 4096 tokens 4096 tokens 4096 tokens Cost (Input / Output per MTok ) $3.00 / $15.00 $15.00 / $75.00 $3.00 / $15.00 $0.25 / $1.25 Training data cut-off Apr 2024 Aug 2023 Aug 2023 Aug 2023\\n\\n8192 output tokens is in beta and requires the header anthropic-beta: max-tokens-3-5-sonnet-2024-07-15. If the header is not specified, the limit is 4096 tokens.\\n\\nPrompt and output performance\\n\\nThe Claude 3 family excels in:\\n\\n\\u200bBenchmark performance: Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing. See the Claude 3 model card for more information.\\n\\nEngaging responses: Claude 3 models are ideal for applications that require rich, human-like interactions.\\n\\nIf you prefer more concise responses, you can adjust your prompts to guide the model toward the desired output length. Refer to our prompt engineering guides for details., source: https://docs.anthropic.com/en/docs/about-claude/models']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chunks[:2] #list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7387e-11df-4d72-9fb0-dda3acc098d8",
   "metadata": {},
   "source": [
    "# Task 2: Generate embeddings from Document chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b57362bd-7e38-445c-ada9-20e57132bbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a documents directory\n",
    "!rm -rf ./documents\n",
    "!mkdir ./documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bc6e60a-aa97-4553-a50d-58649e84df60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content: Anthropic home page\\n\\nLearn about Cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content: Model comparison\\n\\nHere is a visuali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content: Output quality: When migrating from p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>content: Claude 2.1 Claude 2 Claude Instant 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>content: Ticket routingSecurity and compliance...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  content: Anthropic home page\\n\\nLearn about Cl...\n",
       "1  content: Model comparison\\n\\nHere is a visuali...\n",
       "2  content: Output quality: When migrating from p...\n",
       "3  content: Claude 2.1 Claude 2 Claude Instant 1....\n",
       "4  content: Ticket routingSecurity and compliance..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the document chunks in a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(document_chunks, columns =['text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ba0a5ff-26a5-4023-b833-fb9f9b418a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:26<00:00,  7.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to generate the embeddings files you will later upload to Cloud Storage\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "index_embeddings = []\n",
    "model = \"models/embedding-001\"\n",
    "\n",
    "for index, doc in tqdm(df.iterrows(), total=len(df), position=0):\n",
    "\n",
    "    response = genai.embed_content(model=model, content=doc['text'], task_type=\"retrieval_query\")\n",
    "\n",
    "    doc_id=f\"{index}.txt\"\n",
    "    embedding_dict = {\n",
    "        \"id\": doc_id,\n",
    "        \"embedding\": response[\"embedding\"],\n",
    "    }\n",
    "    index_embeddings.append(json.dumps(embedding_dict) + \"\\n\")\n",
    "    \n",
    "    with open(f\"documents/{doc_id}\", \"w\") as document:\n",
    "          document.write(doc['text'])\n",
    "    \n",
    "with open(\"embeddings.json\", \"w\") as f:\n",
    "    f.writelines(index_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93913e92-4c3f-46cc-9498-cde46fe559f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "#uploading local emeddings.json to gcs bucket\n",
    "source_file = '/home/jupyter/embeddings.json'\n",
    "destination_blob_name = 'embeddings/embeddings.json' # Adjust if needed\n",
    "\n",
    "client = storage.Client(project=PROJECT_ID)\n",
    "bucket = client.bucket(PROJECT_ID)\n",
    "blob = bucket.blob(destination_blob_name)\n",
    "blob.upload_from_filename(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa9c1278-41f3-4892-bd7d-a9d6eb7848c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['gsutil', '-q', 'cp', '-r', './documents', 'gs://qwiklabs-gcp-00-f934b9efbd16/documents'], returncode=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the embedding files to Cloud Storage\n",
    "# This step will take a few minutes to complete\n",
    "import subprocess\n",
    "gsutil_command = f\"gsutil -q cp -r './documents' gs://{PROJECT_ID}/documents\"\n",
    "\n",
    "subprocess.run(['gsutil', '-q', 'cp', '-r', './documents', f'gs://{PROJECT_ID}/documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a056208e-7570-4005-b274-90e62d539fb9",
   "metadata": {},
   "source": [
    "# Task 3. Create a Vertex AI Vector Store index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7566d26d-d5eb-4774-80a3-dc61b570fd93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/802092767636/locations/us-central1/indexes/4085974324815593472/operations/1415441072653336576\n",
      "MatchingEngineIndex created. Resource name: projects/802092767636/locations/us-central1/indexes/4085974324815593472\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/802092767636/locations/us-central1/indexes/4085974324815593472')\n"
     ]
    }
   ],
   "source": [
    "# Create the Vertex AI Vector Search index\n",
    "# This step will take several minutes to complete\n",
    "# Wait for this cell to complete before proceeding\n",
    "index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "      display_name=\"vertex_docs\",\n",
    "      contents_delta_uri=f\"gs://{PROJECT_ID}/embeddings\",\n",
    "      dimensions=768,\n",
    "      approximate_neighbors_count=150,\n",
    "      distance_measure_type=\"DOT_PRODUCT_DISTANCE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ced8d73-3b98-4e55-89ca-a29bcb086d61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/802092767636/locations/us-central1/indexEndpoints/9150342474537893888/operations/4829169590200172544\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/802092767636/locations/us-central1/indexEndpoints/9150342474537893888\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/802092767636/locations/us-central1/indexEndpoints/9150342474537893888')\n"
     ]
    }
   ],
   "source": [
    "index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=\"vertex_docs\",\n",
    "    description=\"Embeddings for the documentation curated from the sitemap.\",\n",
    "    public_endpoint_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b42d4077-275f-43cf-8c55-993e0880d651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/802092767636/locations/us-central1/indexEndpoints/9150342474537893888\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/802092767636/locations/us-central1/indexEndpoints/9150342474537893888/operations/947629661360226304\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/802092767636/locations/us-central1/indexEndpoints/9150342474537893888\n"
     ]
    }
   ],
   "source": [
    "# This step will take up to 20 minutes to complete\n",
    "# You can view the deployment in the Vertex AI console on the \"Vector Search\" tab\n",
    "# Wait for this cell to complete before proceeding\n",
    "index_endpoint = index_endpoint.deploy_index(\n",
    "    index=index, deployed_index_id=\"vertex_index_deployment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "877608b4-9496-48c5-8513-799d6324f3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[index_endpoint: \"projects/802092767636/locations/us-central1/indexEndpoints/9150342474537893888\"\n",
       "deployed_index_id: \"vertex_index_deployment\"\n",
       "]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_RESOURCE_NAME=index.resource_name\n",
    "index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)\n",
    "\n",
    "deployed_index = index.deployed_indexes\n",
    "deployed_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a81baa-a4f6-4712-8db2-339b3ca74e35",
   "metadata": {},
   "source": [
    "# Task 4: Search Vector Store, add result as context to a query (without using a LangChain Chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9f563bb-4417-4eac-b675-2377e151357d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In the next cells you will query the model directly using the Vertex AI python SDK\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores.matching_engine import MatchingEngine\n",
    "from langchain.agents import Tool\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "def search_vector_store(question):\n",
    "\n",
    "    vector_store = MatchingEngine.from_components(\n",
    "                        index_id=INDEX_RESOURCE_NAME,\n",
    "                        region=REGION,\n",
    "                        embedding=embeddings,\n",
    "                        project_id=PROJECT_ID,\n",
    "                        endpoint_id=deployed_index[0].index_endpoint,\n",
    "                        gcs_bucket_name=f\"{PROJECT_ID}\")\n",
    "    \n",
    "    relevant_documentation=vector_store.similarity_search(question, k=8)\n",
    "    context = \"\\n\".join([doc.page_content for doc in relevant_documentation])[:10000]\n",
    "    return str(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42442602-f577-4cb2-b4a9-e26fa2425cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "import warnings\n",
    "\n",
    "# filter warnings for unused libs\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def ask_question(question):\n",
    "    context = search_vector_store(question)\n",
    "\n",
    "    prompt=f\"\"\"\n",
    "        Follow exactly those 3 steps:\n",
    "        1. Read the context below and aggregrate this data\n",
    "        Context : {context}\n",
    "        2. Answer the question using only this context\n",
    "        3. Show the source for your answers\n",
    "        User Question: {question}\n",
    "\n",
    "\n",
    "        If you don't have any context and are unsure of the answer, reply that you don't know about this topic.\n",
    "        \"\"\"\n",
    "\n",
    "    model = GenerativeModel(\"gemini-pro\")\n",
    "    response = model.generate_content(prompt)\n",
    "\n",
    "    return to_markdown(f\"Question: \\n{question} \\n\\n Response: \\n {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61376c0e-0447-4527-b212-e65f6b128fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Question: \n",
       "> How do I reduce prompt leaks? \n",
       "> \n",
       ">  Response: \n",
       ">  ##  How to Reduce Prompt Leaks on Anthropic's Claude\n",
       "> \n",
       "> A prompt leak occurs when sensitive information \"hidden\" within the prompt gets unintentionally revealed in Claude's output. While there's no foolproof method, these strategies can significantly decrease the risk:\n",
       "> \n",
       "> **Before You Begin:**\n",
       "> \n",
       "> - Use leak-resistant techniques only when necessary, as they can impact other aspects of the model's performance.\n",
       "> - First, try monitoring techniques like output screening or post-processing to catch leaks before implementing more complex strategies.\n",
       "> \n",
       "> **Strategies to Reduce Prompt Leak:**\n",
       "> \n",
       "> **1. Separate Context from Queries:**\n",
       "> \n",
       "> * Isolate key information and context from user queries using system prompts. \n",
       "> * Emphasize key instructions in the User turn, then reiterate them in the Assistant turn.\n",
       "> \n",
       "> **2. Use Post-Processing:**\n",
       "> \n",
       "> * Filter outputs using regular expressions, keyword filtering, or other text processing methods.\n",
       "> * Use a prompted LLM to identify nuanced leaks.\n",
       "> \n",
       "> **3. Avoid Unnecessary Details:**\n",
       "> \n",
       "> * Only provide information Claude needs to perform the task. Extra content can distract from \"no leak\" instructions.\n",
       "> \n",
       "> **4. Regular Audits:**\n",
       "> \n",
       "> * Periodically review prompts and outputs for potential leaks.\n",
       "> \n",
       "> **Remember:** Balance is key. The goal is to prevent leaks while maintaining performance. Overly complex leak prevention can be detrimental.\n",
       "> \n",
       "> **Source:**\n",
       "> \n",
       "> This response is based on information from the Anthropic documentation on prompt engineering and specifically the section on \"Reduce prompt leak\":\n",
       "> \n",
       "> * https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-prompt-leak\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_question(\"How do I reduce prompt leaks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "edef10e5-28ab-49f1-bc35-a783ef03e572",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Question: \n",
       "> What use cases and capabilities does Anthropic support? \n",
       "> \n",
       ">  Response: \n",
       ">  ## Anthropic's Capabilities and Use Cases \n",
       "> \n",
       "> **Capabilities:**\n",
       "> \n",
       "> * **Text and code generation:** \n",
       ">     * Generate text that adheres to brand voice for customer-facing experiences.\n",
       ">     * Create production-level code.\n",
       ">     * Generate code snippets or templates based on diagrams.\n",
       ">     * Build automatic translation features between languages.\n",
       ">     * Support legal use cases with high-quality technical analysis.\n",
       "> * **Vision:** \n",
       ">     * Analyze visual input, extract insights from charts and graphs.\n",
       ">     * Generate code from images.\n",
       ">     * Describe images for visually impaired users.\n",
       "> * **Tool use:** \n",
       ">     * Interact with external client-side tools and functions.\n",
       ">     * Reason, plan, and execute actions.\n",
       ">     * Generate structured outputs through API calls.\n",
       "> \n",
       "> **Use Cases:**\n",
       "> \n",
       "> * **User Guides:** Create in-depth documentation on a variety of topics.\n",
       "> * **API Reference:** Provide comprehensive documentation on the Anthropic API.\n",
       "> * **Prompt Library:** Offer a collection of example prompts for various use cases.\n",
       "> * **Release Notes:** Track changes and updates to the Anthropic platform.\n",
       "> * **Build with Claude Contest:** Encourage and reward developers for building innovative applications with Claude.\n",
       "> \n",
       "> **Source:** Anthropic documentation, specifically the \"Get started\" and \"Use cases\" sections.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_question(\"What use cases and capabilities does Anthropic support?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730748e8-587d-4a07-b707-9f945e6ec96a",
   "metadata": {},
   "source": [
    "# Task 5: Create Retrieval Augmentation Generation application using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0e958-9d7b-44f0-8893-a508250fa836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To answer questions and chain together the prompt, vector search, returned context and model input use a LangChain \"Chain\"\n",
    "# In this case you will use the RetrievalQA chain which is commonly used for Question/Answering applications\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# initialize model using chat\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.0, convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2d89b2-7cab-4b72-ab2c-c0c931c777ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "    Follow exactly those 3 steps:\n",
    "    1. Read the context below and aggregrate this data\n",
    "    Context : {context}\n",
    "    \n",
    "    2. Answer the question using only this context\n",
    "    3. Show the source for your answers\n",
    "    User Question: {question}\n",
    "\n",
    "    If you don't have any context and are unsure of the answer, reply that you don't know about this topic.\n",
    "    \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"context\",  \"question\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4576213f-c4f0-4603-9ffb-5f4692f425e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores.matching_engine import MatchingEngine\n",
    "\n",
    "vector_store = MatchingEngine.from_components(\n",
    "    index_id=INDEX_RESOURCE_NAME,\n",
    "    region=REGION,\n",
    "    embedding=embeddings,\n",
    "    project_id=PROJECT_ID,\n",
    "    endpoint_id=deployed_index[0].index_endpoint,\n",
    "    gcs_bucket_name=f\"{PROJECT_ID}\"\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type='similarity',\n",
    "    search_kwargs={'k': 1}\n",
    ")\n",
    "\n",
    "# Test the retriever with a simple search performed above\n",
    "to_markdown(retriever.get_relevant_documents(\"How do I get started with Anthropic?\")[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa14bf-0cab-4955-8fb2-d44682c52756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=model,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b756d95c-fe7f-4eaa-b1c7-0fa6f3fb5187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_question(question: str):\n",
    "    response = qa({\"query\": question})\n",
    "\n",
    "    # since k is set to 1 only return the first source retrieved\n",
    "    source = response['source_documents']\n",
    "    \n",
    "    return to_markdown(f\"Response: \\n\\n {response['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220d283-bf02-4a4b-9975-dc3d0a4c2b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: You will see a library warning when running this step\n",
    "ask_question(\"How do I get started with Anthropic?\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-16.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-16:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
